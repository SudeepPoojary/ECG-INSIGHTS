{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"14whZPzYn_-NxeDDfcBJ-gnEmLc8-awQn","authorship_tag":"ABX9TyOl9mvmTChWjjEdv/BjxHOo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPPRmZQ-dNG8","executionInfo":{"status":"ok","timestamp":1709947437111,"user_tz":-330,"elapsed":16111,"user":{"displayName":"Sudeep K","userId":"17557597768774694008"}},"outputId":"21f16e3b-62bc-4922-f0bc-d515d3f2d6d7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Spd8YBKf4nK"},"outputs":[],"source":["import os\n","import re\n","from skimage.filters import threshold_otsu, gaussian\n","from skimage import measure\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from skimage.io import imread\n","from skimage import color\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","\n","# Define the base output directory\n","base_output_dir = '/content/drive/MyDrive/MAJOR_PROJECT/preprocessed_data/'\n","\n","# Function to extract only signal from images\n","def extract_signal_leads(Leads, folder_name, parent, output_dir):\n","    for x, y in enumerate(Leads):\n","        fig1, ax1 = plt.subplots()\n","        #set fig size\n","        #fig1.set_size_inches(20, 20)\n","\n","        #converting to gray scale\n","        grayscale = color.rgb2gray(y)\n","        #smoothing image\n","        blurred_image = gaussian(grayscale,sigma=0.7)\n","        #thresholding to distinguish foreground and background\n","        #using otsu thresholding for getting threshold value\n","        global_thresh = threshold_otsu(blurred_image)\n","\n","        #creating binary image based on threshold\n","        binary_global = blurred_image < global_thresh\n","\n","        #resize image\n","        if x!=12:\n","            binary_global = resize(binary_global, (300, 450))\n","\n","        ax1.imshow(binary_global,cmap=\"gray\")\n","        ax1.axis('off')\n","        ax1.set_title(\"pre-processed Leads {} image\".format(x+1))\n","        plt.close('all')\n","        plt.ioff()\n","        #save the image\n","        fig1.savefig(os.path.join(output_dir, 'images', folder_name, 'Lead_{x}_preprocessed_Signal.png'.format(x=x+1)))\n","\n","        fig7, ax7 = plt.subplots()\n","        plt.gca().invert_yaxis()\n","\n","        #find contour and get only the necessary signal contour\n","        contours = measure.find_contours(binary_global,0.8)\n","        contours_shape = sorted([x.shape for x in contours])[::-1][0:1]\n","        for contour in contours:\n","            if contour.shape in contours_shape:\n","                test = resize(contour, (255, 2))\n","                ax7.plot(test[:, 1], test[:, 0],linewidth=1,color='black')\n","        ax7.axis('image')\n","        ax7.set_title(\"Contour {} image\".format(x+1))\n","        plt.close('all')\n","        plt.ioff()\n","        #save the image\n","        fig7.savefig(os.path.join(output_dir, 'images', folder_name, 'Lead_{x}_Contour_Signal.png'.format(x=x+1)))\n","        lead_no = x\n","        scale_csv_1D(test, lead_no, folder_name, output_dir)\n","\n","\n","def Convert_Image_Lead(image_file, parent_folder, output_dir):\n","    image = imread(os.path.join(parent_folder, image_file), plugin='matplotlib')\n","    #dividing the ECG leads from 1-13 from the above image\n","    Lead_1 = image[300:600, 150:643]\n","    Lead_2 = image[300:600, 646:1135]\n","    Lead_3 = image[300:600, 1140:1626]\n","    Lead_4 = image[300:600, 1630:2125]\n","    Lead_5 = image[600:900, 150:643]\n","    Lead_6 = image[600:900, 646:1135]\n","    Lead_7 = image[600:900, 1140:1626]\n","    Lead_8 = image[600:900, 1630:2125]\n","    Lead_9 = image[900:1200, 150:643]\n","    Lead_10 = image[900:1200, 646:1135]\n","    Lead_11 = image[900:1200, 1140:1626]\n","    Lead_12 = image[900:1200, 1630:2125]\n","    Lead_13 = image[1250:1480, 150:2125]\n","\n","    #list of leads\n","    Leads=[Lead_1,Lead_2,Lead_3,Lead_4,Lead_5,Lead_6,Lead_7,Lead_8,Lead_9,Lead_10,Lead_11,Lead_12,Lead_13]\n","\n","    #folder_name to store lead_images\n","    folder_name= re.sub('.jpg', '',image_file)\n","\n","    #loop through leads and create seperate images\n","    for x, y in enumerate(Leads):\n","        fig, ax = plt.subplots()\n","        ax.imshow(y)\n","        ax.axis('off')\n","        ax.set_title(\"Leads {0}\".format(x+1))\n","\n","        # Ensure the output directory for images exists\n","        image_output_dir = os.path.join(output_dir, 'images', folder_name)\n","        if not os.path.exists(image_output_dir):\n","            os.makedirs(image_output_dir)\n","\n","        # Save the image\n","        plt.close('all')\n","        plt.ioff()\n","        fig.savefig(os.path.join(image_output_dir, 'Lead_{x}_Signal.png'.format(x=x+1)))\n","\n","    extract_signal_leads(Leads, folder_name, parent_folder, output_dir)\n","\n","\n","def convert_csv(test, lead_no, folder_name, output_dir):\n","    target = folder_name[0:2]\n","    df = pd.DataFrame(test, columns=['X', 'Y'])\n","    df['Target'] = target\n","    fig5, ax5 = plt.subplots()\n","    # Convert to CSV\n","    df.to_csv(os.path.join(output_dir, 'csv', folder_name, '{lead_no}.csv'.format(lead_no=lead_no+1)), index=False)\n","\n","\n","#Scaling csv data using MinMaxScaler\n","def scale_csv(test, lead_no, folder_name, output_dir):\n","    target = folder_name[0:2]\n","    scaler = MinMaxScaler()\n","    fit_transform_data = scaler.fit_transform(test)\n","    Normalized_Scaled = pd.DataFrame(fit_transform_data, columns=['X', 'Y'])\n","    Normalized_Scaled = Normalized_Scaled.T\n","    Normalized_Scaled['Target'] = target\n","    if os.path.isfile(os.path.join(output_dir, 'csv', 'Scaled_{lead_no}.csv'.format(lead_no=lead_no+1))):\n","        Normalized_Scaled.to_csv(os.path.join(output_dir, 'csv', 'Scaled_{lead_no}.csv'.format(lead_no=lead_no+1)), mode='a', header=False, index=False)\n","    else:\n","        Normalized_Scaled.to_csv(os.path.join(output_dir, 'csv', 'Scaled_{lead_no}.csv'.format(lead_no=lead_no+1, folder_name=folder_name)), index=False)\n","\n","\n","def scale_csv_1D(test, lead_no, folder_name, output_dir):\n","    target = folder_name[0:2]\n","    scaler = MinMaxScaler()\n","    fit_transform_data = scaler.fit_transform(test)\n","    Normalized_Scaled = pd.DataFrame(fit_transform_data[:, 0], columns=['X'])\n","    fig6, ax6 = plt.subplots()\n","    ax6.plot(Normalized_Scaled, linewidth=1, color='black', linestyle='solid')\n","    fig6.savefig(os.path.join(output_dir, 'images', folder_name, 'ID_Lead_{lead_no}_Signal.png'.format(lead_no=lead_no+1)))\n","    Normalized_Scaled = Normalized_Scaled.T\n","    Normalized_Scaled['Target'] = target\n","    if os.path.isfile(os.path.join(output_dir, 'csv', 'scaled_data_1D_{lead_no}.csv'.format(lead_no=lead_no+1))):\n","        Normalized_Scaled.to_csv(os.path.join(output_dir, 'csv', 'scaled_data_1D_{lead_no}.csv'.format(lead_no=lead_no+1)), mode='a', header=False, index=False)\n","    else:\n","        Normalized_Scaled.to_csv(os.path.join(output_dir, 'csv', 'scaled_data_1D_{lead_no}.csv'.format(lead_no=lead_no+1, folder_name=folder_name)), index=False)\n","\n","\n","normal_parent_dir = '/content/drive/MyDrive/MAJOR_PROJECT/ECG_IMAGES_DATASET/Normal Person ECG Images (284x12=3408)'\n","abnormal_parent_dir = '/content/drive/MyDrive/MAJOR_PROJECT/ECG_IMAGES_DATASET/ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n","MI_parent_dir = '/content/drive/MyDrive/MAJOR_PROJECT/ECG_IMAGES_DATASET/ECG Images of Myocardial Infarction Patients (240x12=2880)'\n","MI_history_parent_dir = '/content/drive/MyDrive/MAJOR_PROJECT/ECG_IMAGES_DATASET/ECG Images of Patient that have History of MI (172x12=2064)'\n","\n","# Types of heart disease\n","Types_ECG = {'Abnormal_hear_beat': abnormal_parent_dir,\n","             'MI': MI_parent_dir,\n","             'History_MI': MI_history_parent_dir,\n","             'Normal': normal_parent_dir}\n","\n","# Loop through folder/files and create separate images of different leads\n","for types, folder in Types_ECG.items():\n","    output_dir = os.path.join(base_output_dir, types)\n","    if not os.path.exists(output_dir):\n","        os.makedirs(os.path.join(output_dir, 'images'))\n","        os.makedirs(os.path.join(output_dir, 'csv'))\n","\n","    for files in os.listdir(folder):\n","        if files.endswith(\".jpg\"):\n","            Convert_Image_Lead(files, folder, output_dir)\n"]}]}